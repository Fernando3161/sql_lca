{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.sankey import Sankey\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "import matplotlib\n",
    "\n",
    "# Ignore specific warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=matplotlib.MatplotlibDeprecationWarning)\n",
    "\n",
    "\n",
    "# File path and sheet details\n",
    "file_path = 'pilot2.xlsx'  # Specify the path to your Excel file\n",
    "sheet_name = 'Upstream tree'  # Specify the sheet name\n",
    "\n",
    "# Sankey Diagram Title\n",
    "impact_name = \"GWP\"  # Global Warming Potential\n",
    "unit_name = \"kg_CO2\"  # Unit of measurement\n",
    "\n",
    "# Options for data processing\n",
    "REMOVE_BACK_INFO = True  # Option to remove background information\n",
    "SHORTEN_LABELS = True  # Option to shorten labels\n",
    "\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(file_path, sheet_name=sheet_name, skiprows=1)\n",
    "\n",
    "# Rename the Result column to a standard name\n",
    "res_name = [col for col in df.columns if \"Result\" in col][0]\n",
    "df.rename(columns={res_name: \"Result\"}, inplace=True)\n",
    "\n",
    "# Drop the 'Direct contribution' column if it exists\n",
    "direc_cont = [col for col in df.columns if \"Direct contribution\" in col][0]\n",
    "df.drop(direc_cont, axis=1, inplace=True)\n",
    "\n",
    "# Filter DataFrame to keep only positive results\n",
    "df = df[df['Result'] > 0]\n",
    "\n",
    "# Drop columns that are completely empty\n",
    "df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Shorten the text to the first 10 characters for all cells\n",
    "#df = df.applymap(lambda x: x[:20] if isinstance(x, str) else x)\n",
    "def shorten_and_suffix(series):\n",
    "    \"\"\"\n",
    "    Shortens strings in the series to the first 20 characters \n",
    "    and adds a suffix to duplicates to ensure uniqueness.\n",
    "\n",
    "    Parameters:\n",
    "    series (pd.Series): A pandas Series that may contain strings.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of modified values from the series.\n",
    "    \"\"\"\n",
    "    seen = {}  # Dictionary to track occurrences of shortened values\n",
    "    result = []\n",
    "\n",
    "    for value in series:\n",
    "        if isinstance(value, str):\n",
    "            short_value = value[:20]  # Shorten to 20 characters\n",
    "            if short_value in seen:\n",
    "                seen[short_value] += 1\n",
    "                result.append(f\"{short_value}_{seen[short_value]}\")  # Add suffix for duplicates\n",
    "            else:\n",
    "                seen[short_value] = 1\n",
    "                result.append(short_value)  # Add shortened value\n",
    "        else:\n",
    "            result.append(value)  # Leave non-string values unchanged\n",
    "\n",
    "    return result\n",
    "\n",
    "# Fill NaN values with \"X\"\n",
    "df = df.fillna(\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_level(row):\n",
    "    \"\"\"\n",
    "    Calculate the level based on the number of consecutive 'X' values\n",
    "    before the first non-'X' value in a row.\n",
    "\n",
    "    Parameters:\n",
    "    row (pd.Series): A row of the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    int: The count of consecutive 'X' values.\n",
    "    \"\"\"\n",
    "    level = 0\n",
    "    for value in row:\n",
    "        if value == 'X':\n",
    "            level += 1  # Increment level for each 'X'\n",
    "        else:\n",
    "            break  # Stop counting at the first non-'X' value\n",
    "    return level\n",
    "\n",
    "# Add a 'Level' column to the DataFrame if it does not exist\n",
    "if \"Level\" not in df.columns:\n",
    "    df['Level'] = df.apply(calculate_level, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_source(df):\n",
    "    \"\"\"\n",
    "    Create a list of source indices based on the DataFrame index.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing the data.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of indices representing the source nodes.\n",
    "    \"\"\"\n",
    "    return df.index.tolist()  # Source is simply the index\n",
    "\n",
    "def create_target(df):\n",
    "    \"\"\"\n",
    "    Create a list of target indices based on the 'Level' column.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing the 'Level' column.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of indices representing the target nodes.\n",
    "    \"\"\"\n",
    "    target = []\n",
    "    for i in range(len(df)):\n",
    "        current_level = df['Level'].iloc[i]\n",
    "        \n",
    "        # Check if it's the first row\n",
    "        if i == 0:\n",
    "            target.append(None)  # No target for the first row\n",
    "            continue\n",
    "        \n",
    "        previous_level = df['Level'].iloc[i - 1]\n",
    "\n",
    "        if current_level == previous_level + 1:\n",
    "            # Connect to the previous row\n",
    "            target.append(i - 1)  # Target is the previous row index\n",
    "        else:\n",
    "            # Find the closest previous row with a lower level\n",
    "            found_target = None\n",
    "            for j in range(i - 1, -1, -1):  # Start from the previous row\n",
    "                if df['Level'].iloc[j] < current_level:\n",
    "                    found_target = j\n",
    "                    break\n",
    "            target.append(found_target)\n",
    "\n",
    "    return target\n",
    "\n",
    "# Create the Source and Target columns in the DataFrame\n",
    "df['Source'] = create_source(df)\n",
    "df['Target'] = create_target(df)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_flows(row):\n",
    "    \"\"\"\n",
    "    Extract the first non-'X' value from a row to determine the flow name.\n",
    "\n",
    "    Parameters:\n",
    "    row (pd.Series): A row of the DataFrame containing flow values.\n",
    "\n",
    "    Returns:\n",
    "    str or None: The first non-'X' value found in the row, or None if all values are 'X'.\n",
    "    \"\"\"\n",
    "    for value in row:\n",
    "        if value != 'X':\n",
    "            return value\n",
    "    return None\n",
    "\n",
    "# Apply the extract_flows function to each row and create a new 'Flow' column in the DataFrame\n",
    "df['Flow'] = df.apply(extract_flows, axis=1)\n",
    "\n",
    "# Create a DataFrame containing unique flow names\n",
    "unique_flows = df['Flow'].unique()\n",
    "df_flows = pd.DataFrame(unique_flows, columns=['Flow'])  # Add a column name for clarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map Source and Target indices to their corresponding flow names\n",
    "df['Target Name'] = df['Target'].apply(lambda x: df['Flow'].iloc[int(x)] if pd.notna(x) else None)\n",
    "df['Source Name'] = df['Source'].apply(lambda x: df['Flow'].iloc[int(x)] if pd.notna(x) else None)\n",
    "\n",
    "# Map Source and Target names to their corresponding indices in the unique flows DataFrame\n",
    "df['Source ID'] = df['Source Name'].apply(\n",
    "    lambda x: df_flows[df_flows['Flow'] == x].index[0] if pd.notna(x) else None\n",
    ")\n",
    "df['Target ID'] = df['Target Name'].apply(\n",
    "    lambda x: df_flows[df_flows['Flow'] == x].index[0] if pd.notna(x) else None\n",
    ")\n",
    "\n",
    "# Create the final DataFrame with relevant columns\n",
    "df2 = df[[\"Result\", \"Source Name\", \"Target Name\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This removes background information to avoid overflow of info.\n",
    "if REMOVE_BACK_INFO:\n",
    "    # Step 1: Identify all nodes that are directly linked to \"market for\" nodes\n",
    "    df2[\"delete\"] = 0  # Initialize the column to mark nodes for deletion\n",
    "    # Create a set of unique source names linked to \"market for\" targets\n",
    "    node_to_delete = set(df2[df2[\"Target Name\"].str.startswith(\"market for\", na=False)][\"Source Name\"].unique())\n",
    "\n",
    "    # Step 2: Iteratively find all nodes linked to already marked nodes\n",
    "    prev_node_count = -1  # To track changes in the node_to_delete set\n",
    "\n",
    "    while len(node_to_delete) > prev_node_count:  # Keep iterating until no new nodes are added\n",
    "        prev_node_count = len(node_to_delete)  # Update the previous count\n",
    "        # Find all rows where the Target Name is in the set of nodes to delete\n",
    "        newly_marked = df2[df2[\"Target Name\"].isin(node_to_delete)][\"Source Name\"].unique()\n",
    "        node_to_delete.update(newly_marked)  # Add newly found nodes to delete set\n",
    "\n",
    "    # Step 3: Mark the rows in the DataFrame for deletion\n",
    "    df2[\"delete\"] = df2[\"Source Name\"].apply(lambda x: 1 if x in node_to_delete else 0)\n",
    "    df2 = df2[df2[\"delete\"] == 0]  # Keep only rows not marked for deletion\n",
    "\n",
    "if SHORTEN_LABELS:\n",
    "    # Remove the \"market for \" prefix from both 'Source Name' and 'Target Name' columns\n",
    "    df2['Source Name'] = df2['Source Name'].str.replace(r'^market for ', '', regex=True)\n",
    "    df2['Target Name'] = df2['Target Name'].str.replace(r'^market for ', '', regex=True)\n",
    "\n",
    "    # Remove the '|' character and everything that follows it in both 'Source Name' and 'Target Name' columns\n",
    "    df2['Source Name'] = df2['Source Name'].str.split('|').str[0]\n",
    "    df2['Target Name'] = df2['Target Name'].str.split('|').str[0]\n",
    "\n",
    "# Calculate the maximum value of the 'Result' column\n",
    "max_value = df2['Result'].max()\n",
    "\n",
    "# Normalize the 'Result' column relative to the maximum value\n",
    "df2['Result'] = (df2['Result'] / max_value) * 100  # Normalize to a scale of 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 54\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m shortened\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Shorten labels\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m shortened_labels \u001b[38;5;241m=\u001b[39m \u001b[43mshorten_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Create a mapping of original labels to their shortened versions\u001b[39;00m\n\u001b[0;32m     57\u001b[0m label_mapping \u001b[38;5;241m=\u001b[39m {label: shortened \u001b[38;5;28;01mfor\u001b[39;00m label, shortened \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(labels, shortened_labels)}\n",
      "Cell \u001b[1;32mIn[51], line 39\u001b[0m, in \u001b[0;36mshorten_labels\u001b[1;34m(labels, max_length)\u001b[0m\n\u001b[0;32m     35\u001b[0m shortened \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# Truncate the label\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m     base_label \u001b[38;5;241m=\u001b[39m \u001b[43mlabel\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     40\u001b[0m     seen[base_label] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# Create a unique label\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Prepare the data for the Sankey diagram\n",
    "sources = df2[\"Source Name\"].tolist()\n",
    "targets = df2[\"Target Name\"].tolist()\n",
    "values = df2[\"Result\"].tolist()\n",
    "\n",
    "# Remove entries where 'Target Name' is None since they don't have a target\n",
    "sources_cleaned = []\n",
    "targets_cleaned = []\n",
    "values_cleaned = []\n",
    "for source, target, value in zip(sources, targets, values):\n",
    "    if target is not None:\n",
    "        sources_cleaned.append(source)\n",
    "        targets_cleaned.append(target)\n",
    "        values_cleaned.append(value)\n",
    "\n",
    "# Create a list of unique labels\n",
    "labels = list(set(sources_cleaned + targets_cleaned))\n",
    "\n",
    "\n",
    "def shorten_labels(labels, max_length=20):\n",
    "    \"\"\"\n",
    "    Shortens labels to a specified maximum length and ensures uniqueness.\n",
    "\n",
    "    Args:\n",
    "        labels (list): List of labels to shorten.\n",
    "        max_length (int): Maximum length for each label.\n",
    "\n",
    "    Returns:\n",
    "        list: List of shortened labels.\n",
    "    \"\"\"\n",
    "    if not SHORTEN_LABELS:\n",
    "        max_length = 500  # Avoid shortening if the option is disabled\n",
    "\n",
    "    seen = defaultdict(int)  # Dictionary to count occurrences\n",
    "    shortened = []\n",
    "\n",
    "    for label in labels:\n",
    "        # Truncate the label\n",
    "        base_label = label[:max_length]\n",
    "        seen[base_label] += 1\n",
    "\n",
    "        # Create a unique label\n",
    "        unique_label = (\n",
    "            f\"{base_label}_{seen[base_label] - 1}\"\n",
    "            if seen[base_label] > 1\n",
    "            else base_label\n",
    "        )\n",
    "        shortened.append(unique_label)\n",
    "\n",
    "    return shortened\n",
    "\n",
    "\n",
    "# Shorten labels\n",
    "shortened_labels = shorten_labels(labels)\n",
    "\n",
    "# Create a mapping of original labels to their shortened versions\n",
    "label_mapping = {label: shortened for label, shortened in zip(labels, shortened_labels)}\n",
    "\n",
    "# Map source and target names to their corresponding index in the shortened labels list\n",
    "source_indices = [\n",
    "    shortened_labels.index(label_mapping[source]) for source in sources_cleaned\n",
    "]\n",
    "target_indices = [\n",
    "    shortened_labels.index(label_mapping[target]) for target in targets_cleaned\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Calculate node sizes based on outgoing flow values\n",
    "node_sizes = np.zeros(len(shortened_labels))\n",
    "\n",
    "# Aggregate values based on source indices\n",
    "for source in source_indices:\n",
    "    node_sizes[source] += values_cleaned[source_indices.index(source)]\n",
    "\n",
    "# Ensure the last node size is 100\n",
    "last_node_index = len(shortened_labels) - 1\n",
    "last_node_size = node_sizes[last_node_index]\n",
    "\n",
    "if last_node_size > 0:  # To avoid division by zero\n",
    "    scaling_factor = 100 / last_node_size\n",
    "    node_sizes *= scaling_factor\n",
    "\n",
    "#########################\n",
    "# Normalize the flow values for color mapping\n",
    "normalized_values = (values_cleaned - np.min(values_cleaned)) / (\n",
    "    np.max(values_cleaned) - np.min(values_cleaned)\n",
    ")\n",
    "\n",
    "# Create a colormap from Matplotlib for the flows\n",
    "flow_cmap = cm.get_cmap(\"viridis\", 256)  # Create a colormap with 256 colors\n",
    "flow_colors = [\n",
    "    mcolors.to_hex(flow_cmap(0.1 + val * 0.7)) for val in normalized_values\n",
    "]  # Flow colors\n",
    "\n",
    "# Normalize node sizes for blue color scale\n",
    "node_sizes_max = np.max(node_sizes)\n",
    "normalized_node_sizes = (\n",
    "    (node_sizes - np.min(node_sizes)) / (node_sizes_max - np.min(node_sizes))\n",
    "    if node_sizes_max - np.min(node_sizes) > 0\n",
    "    else np.zeros(len(node_sizes))\n",
    ")\n",
    "\n",
    "# Create a colormap from Matplotlib for the nodes\n",
    "node_cmap = cm.get_cmap(\"Blues\", 256)  # Create a colormap with 256 colors\n",
    "node_colors = [\n",
    "    mcolors.to_hex(node_cmap(0.5 + val * 0.5)) for val in normalized_node_sizes\n",
    "]  # Node colors\n",
    "\n",
    "\n",
    "# Create the Sankey diagram using Plotly\n",
    "fig = go.Figure(\n",
    "    go.Sankey(\n",
    "        orientation=\"v\",\n",
    "        node=dict(\n",
    "            pad=50,  # Increase the pad value for more horizontal spacing\n",
    "            thickness=20,\n",
    "            line=dict(color=\"black\", width=0.5),\n",
    "            label=shortened_labels,  # Use display labels for the plot\n",
    "            color=node_colors,  # Blue scale for nodes\n",
    "            hoverlabel=dict(\n",
    "                bgcolor=\"rgba(0,0,0,0)\"\n",
    "            ),  # Set label background to transparent\n",
    "        ),\n",
    "        link=dict(\n",
    "            source=source_indices,  # Indices of the source nodes\n",
    "            target=target_indices,  # Indices of the target nodes\n",
    "            value=values_cleaned,  # Flow values\n",
    "            color=flow_colors,  # Color from Matplotlib colormap for flows\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update layout to set the height of the figure\n",
    "fig.update_layout(\n",
    "    title_text=f\"Sankey Diagram | {impact_name} | Max Value: {max_value:.2f} {unit_name}\",\n",
    "    font_size=10,\n",
    "    height=800,  # Adjust height as needed\n",
    "    width=800,\n",
    ")\n",
    "\n",
    "# Add hovertemplate to the links to show full names\n",
    "fig.update_traces(\n",
    "    link=dict(\n",
    "        hovertemplate=\"From: %{source.label}<br>To: %{target.label}<br>Value: %{value}\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Save the figure as an HTML file\n",
    "fig.write_html(f\"sankey_diagram_{impact_name}.html\")\n",
    "\n",
    "# Display the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88816947, 0.675304  , 0.88209399, 1.        , 0.88995637,\n",
       "       0.06349056, 0.07182427, 0.03769071, 0.49625721, 0.36576882,\n",
       "       0.03309157, 0.48746622, 0.03309157, 0.13031735, 0.684095  ,\n",
       "       0.29776065, 1.        , 0.09528691, 0.68696656, 0.88995637,\n",
       "       0.2968828 , 0.        , 0.68589977, 0.02028006, 0.13009085,\n",
       "       0.12266768, 0.10289083, 0.09528691, 0.17709764, 0.8658511 ,\n",
       "       0.27050809])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_node_sizes\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataEval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
